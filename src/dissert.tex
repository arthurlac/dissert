\documentclass[a4paper,10pt]{article}
\usepackage{listings}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{parskip}
\usepackage{stackrel}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{example}{Example}[section]
\newtheorem{theorem}{Thereom}[section]

\usepackage{tikz-cd}
\usetikzlibrary{arrows}
\tikzset{
    commutative diagrams/.cd,
    arrow style=tikz,
    diagrams={>=space}
}
\tikzcdset{
    arrow style=tikz,
    diagrams={>={Straight Barb[scale=0.8]}}
}

\setlength{\parindent}{0pt}
\setlength{\parskip}{1em}

\title{A comparison of algebraic effects and monads}

\begin{document}
\section{Abstract}

KEY IDEAS:
Monads and Computation\\
Notions of Computation Determine Monads\\
Algebraic Effects\\
Rewriting our examples\\
Purely Functional Data structures\\
Why Functional Programming Matters\\
Why functional Progamming matters\\
Conclusion: category theory times functional programming matters\\
Category theory as a framework for better software\\
mathematics in general as a powerful tool to understand the world\\


Effects are tricky, and essential!
Programmers have long sought to make them more predictable;
this may come at the cost of complexity.

Most programmers are unaware, or unconvinced, of monads and algebraic effects.
This paper will attempt to introduce them and make case a for their use.

Elucidate the relation between monads and algebraic effects
and their effectiveness as programming techniques.
I will present example code showing
Demonstrate monad-like programming techniques are already common in imperative languages
Explain where monad-like patterns arise in imperative programming and how monads are often a better alternative
THE KEY POINT IS MONADS ARE GREAT FOR STRUCTURING PROGRAMS TO BE understandable/reliable/correct

Finally I will present an abridged version which forgoes some theory and background
with the goal of introducing and advocating for the concepts
target audience being programmers
As such the success can be judged by how well it explains the use and benefits of both monads and algebraic effects.

\pagebreak
\tableofcontents
\pagebreak

\section{What are effects?}
Firstly, if we are going to assert effects are essential,
we should define what an effect exactly is.

"Haskell purity allows compiler to call only functions whose results are really required to calculate final value of high-level function (i.e., main) - this is called lazy evaluation. It's great thing for pure mathematical computations, but how about I/O actions? Function like:

putStrLn "Press any key to begin formatting"
can't return any meaningful result value, so how can we ensure that compiler will not omit or reorder its execution?"

\begin{example}
    We can give several categories !!!! of computational effects
    which illustrate
    \begin{itemize}
        \item Input/Output
        \item Mutable state
        \item Exceptions
        \item Non-Determinism and Probabilistic Non-Determinism
        \item Continuations
    \end{itemize}
\end{example}

Note that effects $\supset$ side effects,
for example input/output and mutable states are side effects
however non-determinism is not.
\begin{definition}
    An \textit{effect} is
\end{definition}

\begin{definition}
    A \textit{side effect} is
"a side effect if it modifies some state outside its scope or has an observable interaction with its calling functions or the outside world besides returning a value."CHANGEME
\cite{hughes1989functional}
\end{definition}

Why do effects make life hard?
Largely because effects mean we can not employ equational reasoning,
this makes engineering larger programs more complicated
A great deal of trouble can happen when something is implicit
rather than explicit.

We want to maximise the amount of erroneous programs the type-checker will not except

type and effect systems
\cite{nielson1999type}
"an effect system labels each function with its possible effects, so a function type is now written %τ →σ τ′, indicating a function that may have effects delimited by σ."

"Gifford and others proposed an effect typing discipline to delimit the scope of computational effects within a program, while Moggi and others proposed monads for much the same purpose. Here we marry effects to monads, uniting two previously separate lines of research. In particular, we show that the type, region, and effect system of Talpin and Jouvelot carries over directly to an analogous system for monads, including a type and effect reconstruction algorithm. The same technique should allow one to transpose any effect system into a corresponding monad system."
"Effect systems are typically found in strict languages, such as FX [GJLS87] (a variant of Lisp), while monads are typically found in lazy languages, such as Haskell "
"writing %Tσ τ for a computation that yields a value in τ and may have effects delimited by σ. Now we havethat(τ→σ τ′)†isτ†→Tστ′†."
\cite{wadler2003marriage}

\subsection{Referential transparency}
\begin{definition}
    An \textit{referential transparency} is
\end{definition}
WIKI REMOVE ME
An expression is said to be referentially transparent if it can be replaced with its corresponding value without changing the program's behavior.[1] As a result, evaluating a referentially transparent function gives the same value for same arguments. Such functions are called pure functions. An expression that is not referentially transparent is called referentially opaque.
\begin{definition}
    An \textit{referential opacity} is
\end{definition}

What does it mean to be pure?
\begin{definition}
    \textit{Purity} means
\end{definition}

Relation to lambda calculus and $\beta$-equality
In a pure language we have $\beta$-equality
in an impure language 

CONC WE NEED EFFECTS BUT THEY ARE TRICKY, SO VERY TRICKY
We have to ask in what ways can we deal with effects?
What tools do we have as a programmer at our disposal here????
Following this we will present two ideas both originating from CT
which give us tools for effectful programming

\pagebreak
\section{Categorical Views of Effects}
\subsection{Overview}
%Category theorists invented monads in the 1960s to concisely of universal algebra􏰊\cite{wadler1990comprehending}
From Moggi’s assignment to each set X of the set TX of values associated with a computational effect,
one has passed to the study of the operations associated with the computational effect
\cite{hyland2007category}
Following Moggi we have \cite{plotkin2001adequacy}
The Lawvere theory LE for exceptions is the free Lawvere theory generated by E operations $raise : 0 \rightarrow  1$,
where E is a set of exceptions.
In terms of operations and equations,
this corresponds to an E-indexed family of nullary operations with no equations.
%The monad on Set generated by LE is TE = − + E. More generally, the forgetful functor UL : Mod(LE,C) C induces the monad
%−+E on C, where E is the E-fold copower of 1, i.e.,  exists in C.
It is shown in [39]
that this countable Lawvere theory induces Moggi’s side-effects monad $(S \times \textrm{-})^S$ on
Set.
\cite{hyland2007category}

Wadler \cite{wadler1990comprehending} demonstrated the use of monads in a pure
functional programming language to simulate effects.

OPERATIONS GENERATE MONADS \cite{plotkin2001adequacy}
Plotkin and Power verified that and, later joined by Hyland, saw that what were then regarded as com- putational effects could, with one exception, fruitfully be seen as an instance and a development of universal algebra: interactive input/output was soon recognised as an example involving no equations; it was seen how to incorporate local state naturally; and the various ways of combining computational effects proved to be simple instances of combining Lawvere theories.


\subsection{Categories}
First we must introduce the concept of \textit{categories},

\begin{definition}
    A \textit{category} $C$ consists of
    \begin{itemize}
        \item A set $Ob\,C$, elements of which are called \textit{objects} of $C$.
        \item For each $X, Y \in Ob\,C$
            a set $Hom(X,Y)$ called the \textit{homset} from $X$ to $Y$.
        \item A \textit{composition function} $\circ$ such that
            \begin{equation}
                \circ : Hom(X,Y) \times Hom(Y,Z) \rightarrow Hom(X,Z)
            \end{equation}
        \item For all $X \in Ob\,C$ an element $Id_X$ of $Hom(X,\ X)$
            such that $f \circ Id_X = Id_Y \circ f = f$
        \item Composition is associative.  $f \circ (g \circ h) = (f \circ g) \circ h$
    \end{itemize}
\end{definition}

\par
An element $f$ of $Hom(X,Y)$ is called an \textit{arrow},
or a \textit{morphism}. The object $X$ is called the \textit{domain} of $f$ and $Y$ is
the \textit{codomain}.\\

\begin{example}
    The immediate example of a category is the category of sets.
    The objects in $C$ are (small) sets,
    a morphism from $X$ to $Y$ is a function $f : X \rightarrow Y$.
    The composition of Set is given by composition of functions,
    and the identity maps are given by the identity functions.
\end{example}

\subsection{Functors}
\begin{definition}
    A \textit{functor} $U : C \rightarrow D$ consists of
    \begin{itemize}
        \item A function $Ob\,U : Ob\,C \rightarrow Ob\,D$.
        \item A function $U : Hom_C(X,Y) \rightarrow Hom_D(UX, UY)$
            such that $U$ respects both composition and identity.
            I.e.
            \begin{equation}
                Uf \circ Ug = U(f \circ g) \quad U\,Id_X = Id_{UX}
            \end{equation}
    \end{itemize}
\end{definition}

\begin{definition}
    An \textit{endofunctor} is a functor $U : C \rightarrow C$;
    i.e. the domain and codomain of the functor are the same category $C$.
\end{definition}

\subsection{Natural transformations}
\begin{definition}
    Given categories $C$ and $D$,
    with functors $U, V : C \rightarrow D$
    a \textit{natural transformation} $\alpha : U \rightarrow V$
    consists of
    \begin{equation}
        \forall\ X \in Ob\,C\ \textrm{a map} \ \alpha_X : UX \rightarrow VX
    \end{equation}
    such that $\forall\ f : X \rightarrow Y$ the following commutes
    \begin{center}
        \begin{tikzcd}[sep=large]
            UX \rar{\alpha_X} \dar[swap]{Uf} & VX \dar{Vf} \\
            UY \rar{\alpha_Y}                & VY
        \end{tikzcd}
    \end{center}
    A natural transformation can be considered a morphism of functors.
\end{definition}

\subsection{Monads}
"Monads are among the most pervasive structures in category theory
and its applications: for example, they are central to the category-theoretic account of universal algebra"
\cite{mac2013categories}
\begin{definition}
    A \textit{monad} is defined as the triple
    \begin{itemize}
        \item An endofunctor $T : C \rightarrow C$
        \item A natural transformation $\eta : 1_{C} \rightarrow T$
        \item A natural transformation $\mu : T^2 \rightarrow T$
    \end{itemize}
    Such that the following diagrams commute
    \begin{center}
        \begin{tikzcd}[sep=large]
            T \rar{\eta_T} \drar[swap]{1_{C}} & T^2 \dar{\mu} & \lar[swap]{T\eta} \dlar{1_{C}} T \\
                                               & T            &
        \end{tikzcd}
        \quad
        \begin{tikzcd}[sep=large]
            T^3 \rar{T\mu} \dar[swap]{\mu_T} & T^2 \dar{\mu} \\
            T^2 \rar[swap]{\mu}                    & T
        \end{tikzcd}
    \end{center}
\end{definition}
%TODO
%which satisfies also an extra equalizing requirement: ηA: A → T A is an equalizer of ηTA and T(ηA), i.e. for any f:B → TA s.t. f;ηTA = f;T(ηA) there exists a unique m:B → A s.t. f = m;ηA3.

\subsection{Kleisli Category}
\begin{definition}
    Given a monad $(T,\eta,\mu)$ over a category $C$,
    the \textit{Kleisli category} $C_T$ consists of
    \begin{itemize}
        \item Objects of $C_T$ are objects from the underlying category $C$.
        \item $Hom_{C_T}(X,Y) = Hom_C (X,TY)$
        \item Identity morphisms in $C_T$ are $\eta$ in $C$
        \item Composition $f \circ g$ is $\mu(Tf)g$
    \end{itemize}
\end{definition}

Composition in $C_T$ can be described in more detail via the operator
\begin{equation}
    (-)^{*} : Hom(X, TY) \rightarrow Hom(TX, TY)
\end{equation}
where given a morphism $f: X \rightarrow TY$ we have
\begin{equation}
    f^{*} = \mu_{Y} \circ Tf
\end{equation}
Note that
\begin{equation}
    \eta_{X}^{*} = Id_{TX}
    \quad\textrm{and}\quad
    f^{*} \circ \eta _{X} = f
\end{equation}
Then we can define the \textit{Kleisli operator} $\gg$ where
\begin{equation}
    g \gg f = g^{*} \circ f
\end{equation}
\begin{equation}
    x
    \stackrel{f}{\rightarrow}     T y
    \stackrel{T g}{\rightarrow}   T T z
    \stackrel{\mu z}{\rightarrow} T z
\end{equation}
where $\gg$ has these axioms
\begin{equation}
    (f \gg g) \gg h \equiv f \gg (g \gg h)
\end{equation}
\begin{equation}
    \eta_Y \gg f \equiv f \equiv f \gg \eta_X
\end{equation}

\subsection{Computational $\lambda$-Calculus}
Moggi \cite{moggi1989computational}
introduced categorical semantics for computation based on monads.
He extended the simply typed lambda-calculus to
the computational lambda-calculus, or $\lambda_c$-calculus,
which allows computations with effects such as
non-determinism, side effects, and continuations.
In this model "a program denotes a morphism from $A$
(the object of values of type $A$) to $TB$
(the object of computations of type B)"
for example
"partial computations (of type $B$) is the lifting $B + \{\bot\}$".
Another example would be the type \texttt{IO Int}
meaning interactive input/output computations of integers.


Cartesian closed category to model the simply typed lambda calculus
A $\lambda_c$-model over a category $C$ with finite products is a strong monad $(T,\eta,\mu,t)$
together with a $T$-exponential for every pair $\langle A, B\rangle$ of objects in $C$
Moggi

To give two examples of the $\lambda_C$-calculus, which we will elaborate on further later,
These examples from \cite{moggi1989computational}\cite{moggi1991notions} will be revisited later.
\vspace{5mm}

\begin{example}
    Non-deterministic computations:
    \begin{itemize}
        \item $T(-)$ is the covariant powerset functor,
            i.e.  $T(A)$ = $P(A)$ and $T(f)(X)$ is the image of X along f
        \item $\eta_A$ is the singleton map $a \rightarrow  \{a\}$
        \item $\mu_A(X)$ is the big union $\bigcup X$
    \end{itemize}
\end{example}

\vspace{5mm}

\begin{example}
    Computations with side-effects:
    \begin{itemize}
        \item $T(-)$ is the functor $(-\times S)^S$, where $S$ is a nonempty set of stores.
            Intuitively a computation takes a store and returns a value together with the modified store.
        \item $\eta_A$ is the map $a \rightarrow (\lambda s:S.\langle a,s \rangle)$
        \item $\mu_A$ is the map $f \rightarrow (\lambda s:S.eval(fs))$,
            i.e. $\mu_A(f)$ is the computation that given a store $s$,
            first computes the pair computation-store $\langle f\prime,s\prime\rangle = fs$
            and then returns the pair value-store $\langle a,s\prime\prime\rangle = f\prime s\prime$.
    \end{itemize}
\end{example}

\subsection{Lawvere Theories}
"a class of theories that can be viewed as categories with a monad, so that any category with a monad is, up to equivalence (of categories with a monad), one of such theories. Such a reformulation in terms of theories is more suitable for formal manipulation and more appealing to those unfamiliar with Category Theory."
\cite{moggi1991notions}

"Computational effects invariably arise from operations such as a nonde- terministic choice operation, operations for writing or reading, or operations for looking up or updating state."
"Our approach relates closely to Moggi’s, but while he emphasised the construction of an object TX of computations of type X as primitive, we give operations a more primitive role, with T X treated as derived."
"All Moggi’s leading examples of monads have countable rank, except for the continuations monad."
^^ reason we can't have continuation AE
"the computational effects we consider are easily described as countable enriched Lawvere theories freely generated by such operations and equations."
"We overview a programme to provide a unified semantics for computational effects based upon the notion of a countable enriched Lawvere theory."\cite{plotkin2004computational}
"The notion of countable enriched Lawvere theory provides us with a natural way to describe how computational effects may be combined. Typically, one takes the disjoint union of the operations, together with all the equations, and adds further equations relating the two classes of operations: one might add no equations, yielding the sum of effects; one might demand the two families of operations commute with each other, yielding the commutative combination of effects; or one might ask for distributivity of one family of operations over the other, or perhaps of each family over the other."
%The countable Lawvere theory LI/O for interactive input/output is the free countable Lawvere theory generated by operations read : I −→ 1
%and write : 1 −→ O, where I is a countable set of inputs and O of outputs. So, interactive input/output is more directly modelled by the countable Lawvere theory than by the corresponding monad T X = μY.(O × Y + Y I + X).
An enriched Lawvere theory is generated by operations subject to equa- tions. Operations appear directly in describing programming languages, but equations do not.
one of the equations for side-effects is
%updateloc,v (updateloc,v′ (x)) = updateloc,v′ (x) and the corresponding program assertion is
%(l := x;let y be !l in M) = (l := x;M[x/y])


\cite{plotkin2001adequacy}

Algebraic effects have a categorical basis in Lawvere Theories
This mathematical background is, regrettably, beyond the scope of this document.
In mathematical practice Lawvere theories arise whenever one has a functor into a category with finite products and one studies the natural transformations between finite products of the functor.
\cite{hyland2007category}

\pagebreak
\section{Monads in the Wild}
Typically a programmer will think of a monad as three function signatures
which correspond to the triple $(T,\eta,\mu)$;
of course much more informally.
Firstly \texttt{fmap} corresponds to the functor $T$,
then we have \texttt{return} and \texttt{join} which correspond to
the natural transformations $\eta$ and $\mu$ respectively.
Sometimes other names are used,
for example \texttt{map} instead of \texttt{fmap}
or \texttt{pure} instead of \texttt{return},
however the semantics are exactly the same.

\begin{equation}
  \begin{split}
    fmap   &:: M x \rightarrow (x \rightarrow y) \rightarrow M y \\
    return &:: x \rightarrow M x                                 \\
    join   &:: M (M x) \rightarrow M x
  \end{split}
\end{equation}

To be a correct monad implementation it must be true that:
\begin{equation}
  \begin{split}
      \lambda f.\lambda x.return\ (fmap\ f\ x)
      &\equiv
      \lambda f.\lambda x.fmap\ (return \circ f)\ x)
      \\
      \lambda f.\lambda x.fmap\ f\ x
      &\equiv
      \lambda f.\lambda x.fmap\ f\ (fmap\ id\ x)
      \\
      \lambda f.\lambda x.join\ (join\ (fmap\ f\ x))
      &\equiv
      \lambda f.\lambda x.join(fmap\ f\ (join\ x))
  \end{split}
\end{equation}

%TODO
Contrast these monad laws with the diagrams
\begin{center}
    \begin{tikzcd}[sep=large]
        T \rar{\eta_T} \drar[swap]{1_{C}} & T^2 \dar{\mu} & \lar[swap]{T\eta} \dlar{1_{C}} T \\
                                           & T            &
    \end{tikzcd}
    \quad
    \begin{tikzcd}[sep=large]
        T^3 \rar{T\mu} \dar[swap]{\mu_T} & T^2 \dar{\mu} \\
        T^2 \rar[swap]{\mu}                    & T
    \end{tikzcd}
\end{center}

For programmers the essence of a monad is \texttt{fmap}
this is because
however one often sees \texttt{bind} where
\begin{equation}
    bind :: M x \rightarrow (x \rightarrow M y) \rightarrow M y
\end{equation}
It is convention to use bind as the infix operator "\texttt{>>=}".
Bind is formulated as
\begin{equation}
    g >>= f = \lambda x. join (g (f x))
\end{equation}
Bind is a hugely useful tool for programmers;
because often we want to sequence

Because \texttt{bind} is often found with \texttt{(fmap,join,return)}
We can reformulate our axioms in terms of bind
indeed the axioms are often reformulated this way because it is simpler.
\begin{equation}
  \begin{split}
      return\ x >>= f     &\equiv f x \\
             m >>= return &\equiv m   \\
      (m >>= f) >>= g     &\equiv m >>= (\lambda x.(fx >>= g))
  \end{split}
\end{equation}

We can further rephrase ourselves in terms
of the \textit{Kleisli composition operator}

\begin{equation}
    kc :: (x \rightarrow M y) \rightarrow (y \rightarrow M z) \rightarrow x \rightarrow M z
\end{equation}
where we have
\begin{equation}
    (f \gg g) \gg h \equiv f \gg (g \gg h)
\end{equation}
\begin{equation}
    return \gg f \equiv f \equiv f \gg return
\end{equation}

Do programming monads need to follow the same rules as category theory monads?
There is no way for the compiler to check these rules so practically the answer is no,
however it is wise for monad implementations to obey them so that
we can chain computations in predictable and understandable ways.

\subsection{State Monad Example}
\subsection{Non-Determinism Monad Example}

\subsection{Monads for Structuring Programs}
In this section I will illustrate how effective monads are when used to structure programs.

Firstly one should note that OCaml has non-nullable types
i.e; one will never see null where one is expecting an
int or a binary tree or anything else.
Null values are always explicit.
The canonical representation of null is the None variant.
Why is this?
Why do we need monads to this?
What do other languages do?
Monads can be used to succinctly and expressively structure computation with the option type.

\begin{verbatim}
  type 'a option = Some 'a | None
  val return : 'a -> 'a option
  val join   : 'a option option -> 'a option
  val fmap   : 'a option -> ('a -> 'b) -> 'b option
\end{verbatim}

The code for these three functions is simple and fairly self-evident.
However from this simple basis we can construct much more complicated programs which we
will be certain will never have a \textit{NullPointerException}.
Furthermore the type system will ensure 
It will refuse to compile nonsensical code which does not type-check.
Such an assurance is invaluable in creating correct programs.
Here it's important to note that the effect is the \textit{NullPointerException};
we deal with it much more cleanly and effectively 100\% of the time using monads.

\begin{verbatim}
  let return a = Some a
  let join = function
      | Some (Some a) -> Some a
      | _ -> None
  let map a f = match a with
      | None -> None
      | Some b -> f b
\end{verbatim}

Consider this example code for searching a trie data structure.
Briefly, a trie is key value data structure;
where the key is a finite sequence of values
(typically a string which is equivalent to a sequence of characters).
Each node has an option value and a list of children.
The root of the trie represents the empty string.
Two auxiliary functions \texttt{find\_child} and \texttt{val\_extract}
are used in the search code; \texttt{val\_extract}
simply returns the first value in a pair,
find child searchs the list of children returning
the node with the matching character given;
that is only should that child exists.

\begin{verbatim}
  type ('k, 'v) t = Trie of 'v option * (('k * ('k, 'v) t) list)
  val find_child  : ('k, 'v) t -> 'k -> ('k, 'v) t option
  val val_extract : ('k, 'v) t -> 'v option
  val create      : 'k list -> 'v -> ('k, 'v) t
  val get         : ('k, 'v) t -> 'k list -> 'v option

  let create key data =
    let rec aux = function
      | []      -> Trie (Some data, [])
      | c :: cs -> Trie (None, [(c, aux cs)])
    in aux key
\end{verbatim}

Create is shown to just illustrate the data structure,
we simply iterate across the list creating a node in the trie for each character
until the list is exhausted at which point we insert the value.

%TODO tikz example of the data structure

In the search code t is the trie, key is a list of characters over which
we iterate the search function. For each character we call find child on
the current node. Find child, if succesful, will return the next node
upon which we continue the search with the remaining characters. Once we
are at the last character we know to try and extract the value from the end
node. The key point here is that using bind allows us to succintly only code
for the happy case but deal with the error case at every step.

\begin{verbatim}
  let get t key =
    let rec search chars t =
        match chars with
        | []      -> val_extract t
        | c :: cs -> bind_search (find_child t c) cs
    and bind_search ot chars = ot >>= search chars
    in search key t
\end{verbatim}

The result type is similar to the option type, however we use an extra type
parameter for the unhappy case, essentially the result type encapsulates 
either an error or a correct computation result. The result monad
corresponds to a generalisation of the exception monad presented by Wadler \cite{wadler1995monads}.

\begin{verbatim}
  type ('a, 'e) result = Ok of 'a | Error of 'e
  val bind : ('a, 'e) result
          -> ('a -> ('b, 'e) result)
          -> ('b, 'e) result
\end{verbatim}

In this example we have a list assocation which is a list of pairs, in this case both
items in the pairs are strings.

\begin{verbatim}
  let list_assoc_to_job la =
    let find k = match List.Assoc.find la k with
      | None -> Error (Err.missing_key k)
      | Some v -> Ok v
    in
    find "name"   >>=                  (fun name   ->
    find "prog"   >>=                  (fun prog   ->
    find "args"   >>= parse_args   >>= (fun args   ->
    find "run_at" >>= parse_run_at >>= (fun run_at ->
      Ok (Job.create name prog args run_at ())
    ))))
\end{verbatim}

Bind is used to succintly short circuit a computation when a value can not be
correctly obtained. As such this allows the program to be structured neatly to return
an error with precise information for which key could not be found or which value could
not be parsed. The result monad is very similar to the option monad. It would be interesting
to examine whether algebraic effects can be used to structure a program in a similar manner.

Typically programming languages allow the elison of the anonymous function on the right hand side
of the bind to simply introduce the binding into the environment;
in this case OCaml ppx extension points are used in the form \textit{let\%bind}.
This is largely just a programmer convienence,
for comparison Haskell offers \textit{do notation} for the same end.

\begin{verbatim}
  let list_assoc_to_job la =
    let find k = match List.Assoc.find la k with
      | None -> Error (Err.missing_key k)
      | Some v -> Ok v
    in
    let%bind name   =  find "name"                     in
    let%bind prog   =  find "prog"                     in
    let%bind args   = (find "args"   >>= parse_args  ) in
    let%bind run_at = (find "run_at" >>= parse_run_at) in
    Ok (Job.create name prog args run_at ())
\end{verbatim}

%%TODO
\subsection{Monads for Imperative Programming}
Imperative programming is undeniably popular, and much closer to how computers physically work,
monads have been concretely shown to be an effective method of replicating
imperative style and retaining benefits of purity \cite{PeytonJones:1993}.
These examples clearly illustrate how useful monads can be for structuring a program,
however the importance and necessity of monads is that for pure functional languages
to be actually useful we require effects. Monads give us means to achieve that.

\begin{verbatim}
    result, err := myFunction()
    if err != nil {
        return nil, err
    }
\end{verbatim}

In the Go programming language one will often see this idiom,
one can easily see the relation to the result monad which we
have demonstrated.
We get this for free with monads!

\begin{verbatim}
    name, err := findName(la)
    if err != nil {
        return nil, err
    }
    prog, err := findProg(la)
    if err != nil {
        return nil, err
    }
    etc...
\end{verbatim}


\subsection{Monad Transformers}
Monad transformers add functionality of one monad to another.
We often find that difficulty arises when trying to compose monads,
say we have a stateful computation a



\pagebreak
\section{Algebraic Effects}

\begin{example}
    Consider the examples of effects we gave in cite
    we will now give the operations which generate those effects
    \begin{itemize}
        \item Input/Output - print
        \item Mutable state - get/set
        \item Exceptions - raise
        \item Non-Determinism and Probabilistic Non-Determinism - choose
        \item Continuations - cont
    \end{itemize}
\end{example}
Algebraic effects, like monads, can be used to model effects in a pure language.
Where Moggi \cite{moggi1989computational} proposed monads to give categorical semantics to computational effects;
Power and Plotkin \cite{Plotkin:2002dw} propose "computational effects as being realised by
families of operations, with a monad being generated by their equational theory".
This means we can treat effects algebraically,
to actually interact with them as programming constructs algebraic effects are paired with
handlers \cite{plotkin2009handlers}.
Where algebraic operations construct effects handlers are the dual, they deconstruct effects.

Theoretical background is, regrettably, beyond the scope of this document.
\begin{definition}
    An operation is !
\end{definition}

the essence is we have operations which generate effects,
which can be dealt with algebraically %(What does algebraic mean
and further which allows generic effects
"Of the various operations, handle is of a different computational character and, although natural, it is not algebraic. Andrzej Filinski (personal communication) describes handle as a deconstructor, whereas the other operations are constructors (of effects). In this paper, we make the notion of constructor precise by identifying it with the notion of algebraic operation."

\begin{itemize}
    \item Eff: Matija Pretnar and Andrej Bauer, 2011-now.
    \item Links : Daniel Hillerström and Sam Lindley, 2015.
    \item Frank: Conor McBride, 2007, 2012.
    \item OCaml+effects: Stephen Dolan, Leo White, KC Sivaramakrishnan, 2016.
\end{itemize}

Currently algebraic effects are a popular area of research,
it has been shown that they can "concisely describe many complex control-flow constructs" \cite{leijen2017type}.
They "provide a modular abstraction for expressing effectful computation"\cite{dolan2015effective},
in this section I will examine to what extent they can be equivalently used to monads and wether
they provide the same benefits.

\begin{verbatim}
effect choice =
  | Choose : bool

effect IO =
  | Print : string -> unit
  | Read : string

effect int_state =
  | Get : int
  | Set : int -> unit

effect scheduler =
  | Spawn : (unit -> unit) -> unit
  | Yield : unit

let incr_twice () : int =
  perform (Set ((perform Get) + 1));
  perform (Set ((perform Get) + 1));
  perform (Print "incremented twice");
  perform Get
\end{verbatim}
%http://gallium.inria.fr/~scherer/doc/effect-handlers-talk.html#/sec-effect-handlers--examples

\subsection{Trie via Algebraic Effects}

\subsection{Draft}

It is important to seperate values from operations, operations give rise to effects,
there is a difference here in being and doing

"As a restriction on general monads, algebraic effects come with various advantages:
they can be freely composed, 
and there is a natural separation between their interface (as a set of operations) and their semantics (as a handler)."

%%"the signature of the effect operations forms a free algebra which gives rise to a free monad. Free monads provide a natural way to give semantics to effects, where handlers describe a fold over the algebra of operations [44]. Using a more operational perspective, we can also view algebraic effects as resumable exceptions (or perhaps as a more structured form of delimited continuations)." \cite{leijen2017type}

Monad transformers can quickly become unwieldy when there are lots of effects to manage, leading to a temptation in larger programs to combine everything into one coarse-grained state and exception monad.

[Programming and Reasoning with Algebraic Effects and Dependent Types]

%%TODO Allow us to reconcile being with doing
%%allowing the programmer to separate the expression of an effectful computation from its implementation."\cite{dolan2015effective}

Algebraic effects are computational effects that can be represented by an equational theory, or algebraic theory, whose operations produce the effects at hand.
Continuations are not algebraic effects.

Algebraic effects allow computational effects to be representable by
effects that allow a representation by opera- tions and equations

\subsection{Rebuilding our trie with algebraic effects}
\subsection{Composing algebraic effects}

\pagebreak
\section{Abridged version}

\pagebreak
\section{Conclusion}

\medskip

\bibliographystyle{unsrt}
\bibliography{dissert}

\end{document}
